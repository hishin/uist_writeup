\section{Introduction}

Audio recordings of speech are a common form of communication that are prevalent across a variety of media, including podcasts, audio books, e-lectures and voice-overs for narrated videos.
%
Creating such audio recordings typically involves three main tasks: writing a script, recording the speech, and editing the recorded audio. 
%
While authors typically start by writing at least a rough script of what they plan to record, in practice, the process of creating the final audio rarely involves a simple linear progression through these steps. A more common workflow is to move back and forth between writing/editing the script, recording/improvising subsets of the speech, and editing together portions of multiple recorded takes.

For example, consider the case of recording the audio for an online lecture. After writing some notes to use as a rough script, the lecturer records a few takes and listens to the speech. She decides that one of the concepts requires a more detailed explanation, so she edits her notes, re-records the relevant speech, and merges the new recording into the final audio. Such updates may also happen in response to feedback from viewers after the lecture is published online. Similarly, when authoring a voice-over for a video, the initial recording may not align perfectly with the visual footage (e.g., some spoken explanations may be too short or too long for the corresponding video clips). The user may need to modify the script and re-record certain sections of the speech. In general, the process of recording and editing the speech together often reveals issues that require going back to edit portions of the script.

Unfortunately, most existing tools for authoring speech recordings do not facilitate this back and forth workflow. Typically, users write and edit the script in a text editing environment and then record and edit the audio in a standard waveform editing tool. The important point is that the written script and the recorded audio are treated as completely separate entities.
%
This separation introduces several workflow problems. When the user records the speech, any deviations from the initial written text (either intentional or not) are not reflected in the script. Evaluating the recordings to decide what takes to choose or what script modifications are necessary requires careful scrubbing through the audio to find the relevant parts. In addition, once the user chooses a particular version of the speech to include, the script no longer matches the speech, which complicates any subsequent edits to the content. Finally, if the user decides to modify a portion of the script, they must figure out what subset to re-record to ensure that the new recording can be merged in without creating audio artifacts (e.g., replacing a single word in a recorded sentence is hard to do since the word may blend seamlessly with the adjacent words).

To address these challenges, we present \systemname\, an interface that supports script writing, speech recording, and audio editing in a unified way. Our key idea is to maintain the notion of a \emph{master-script} that always reflects the current state of the project, including unrecorded, recorded, improvised and edited portions of the script. We  use speech recognition to transcribe the audio into text, and solve the task of editing together multiple recordings and syncing audio with the script like a text differencing and merging problem. To help users maintain a consistent master-script, \systemname\ provides semi-automated tools for merging recorded takes into the master-script and visualizations that indicate what portions of the script need to be recorded (or re-recorded) in response to edits to the script. The combination of these features enables users to move back and forth between script editing, speech recording and audio editing in a seamless fashion.

We have used our interface to create audio recordings in a variety of workflows, including a collaborative scenario between two users, recording a fairly detailed script, and recording without any script. We also conducted informal evaluations where users created their own audio recordings to summarize technical articles.   In another pilot study, users compared our interface to a state-of-the-art text-based audio editing tool for the task of creating an audio recording from multiple raw recordings. The results demonstrate that our interface supports a wide range of workflows and enables first-time users to  easily author high-quality speech recordings. User feedback suggest that the intergration of script and audio through the master-script greatly facilitates the authoring process. 

\if 0
Audio recordings are a common form of communication used in voice-overs, podcasts, audio books and e-lectures. Closest to everyday conversation, audio recording\ is a medium with relatively low barriers to entry. It is used by many laymen who are not professional producers or writers. A common workflow for creating such audio recordings involves three main tasks: writing a script, recording audio and editing audio. In many cases, users go back and forth between these tasks in order to create the final audio. 

Consider the case of recording the audio for an online lecture. The lecturer prepares lecture notes or slides and uses it as a rough script while recording. After recording a couple of takes, she decides that it would be useful to insert a further explanation about one of the points. She edits the notes and re-records that part. The final audio is created by cutting and merging the multiple recordings. After the initial release on an online platform, viewers leave feedback. The lecturer realizes that many people are confused about a particular point. In order to address their concern, she revises the notes and also  re-records that part with a new explanation and more examples. The audio is re-edited and updated. 

Similarly, consider recording a voice-over for a video. The narrator does an initial recording based on a loosely prepared script. Afterwards, while placing it on top of the video , the narrator realizes that additional shots are needed to make the narrative clear. New shots are inserted, the script is edited to include matching narrative and parts of the audio is re-recorded.
These are but a few of many scenarios where
users go back and forth between script writing, audio
recording and audio editing.



Most existing tools for script writing and audio recording/editing treat the two resources (i.e. script and audio) as completely separate. Users create and edit the script document using one tool, and record and edit the audio using another tool.
The task of making a connection between the script and the audio is left for the user to do manually. This is the case even
when for audio where scripts play a key role.
  
% Moreover, traditional tools provide many features that are useful for manipulating audio waveforms, but that are not directly relevant for creating audio stories. Their complex user interface can be a overwhelming for novice users. 

We present an interface that links and supports all of the three main tasks in audio production: script writing, audio recording and audio editing. Our system addresses challenges that span the process of creating audio recordings, including (1) linking the script  with audio recordings, (2) supporting a dynamic workflow, and (3) merging multiple audio segments into a single final track. Our interface is inspired from familiar document editors and text merge tools, which are easy to learn.
\fi
